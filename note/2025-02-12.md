data loader의 역할
- 배치 처리: 메모리 효율성 및 학습 속도 향상
- 데이터 셔플링: 모델의 일반화 성능 향상
- 병렬 처리: 데이터 로딩을 병렬로 처리하여 학습 속도 최적화
- 데이터 전처리 자동화: 이미지 정규화, 리사이즈 등

### CNN
- 합성곱(convolution): 하나의 작은 행렬(필터 또는 커널)을 큰 행렬(입력 데이터) 위에서 슬라이딩 시키면서 점곱(dot product)을 계산하는 연산
- dot product: 두 개의 같은 차원 벡터 간의 곱셈과 덧셈 연산을 통해 하나의 스칼라 값을 얻는 연산
- padding: 입력데이터와 출력 데이터의 크기를 맞추기 위해 합성곱 연산 수행 전 사용

곱셈과 관련된 행렬 연산
### **행렬 곱셈과 관련된 다양한 연산 설명**

##### **일반 행렬 곱 (Matrix Multiplication)**
- 기호/표기법: A×B
- 설명: 두 개의 행렬 A와 B의 각 행 벡터와 열 벡터 간의 내적을 수행
- 조건: A의 열 개수와 B의 행 개수가 동일
- 결과 형태: 새로운 행렬이 생성 (ex. A가 m×n, B가 n×p 인 경우 A×B 행렬은 m×p)
- 활용 분야: 선형 변환, 데이터 변환, ML 모델의 가중치 계산, 딥러닝에서 뉴런 간 연결 연산 등
##### 아마다르 곱 (원소별 곱, Hadamard Product)
- 기호/표기법: A⊙B
- 설명: 각 위치의 원소끼리 곱하는 연산
- 조건: A의 크기와 B의 크기가 동일
- 결과 형태: 입력 행렬과 같은 크기의 행렬
- 활용 분야: CNN의 마스킹, 특성 강조 또는 신경망에서 활성화된 뉴런의 마스크 처리
##### 점곱 (Dot Product)
- 점곱은 내적의 특수한 경우임
- 기호/표기법: a⋅b
- 설명: 두 벡터의 원소를 위치별로 곱한 후, 그 결과를 모두 더한 값 (아마다르 곱 결과를 모두 더한 값과 동일)
- 조건: 두 벡터의 차원이 동일
- 의미: 두 벡터의 방향과 유사성을 수치적으로 표현
- 결과 형태: 하나의 스칼라 값
- 활용 분야: 벡터 간 유사도 계산(예: 코사인 유사도), 신경망 활성화 함수 입력 등
##### 컨볼루션 (합성곱, Convolution)
- 기호/표기법: A∗K
- 설명: 작은 필터(커널)를 입력 데이터 위에서 슬라이딩하면서 원소별 곱셈 수행 후 합산을 진행
- 조건: 일반적으로 필터(K)의 크기가 데이터(A)보다 작아야 함
- 결과 형태: 입력 데이터보다 작은 크기의 특징 맵(Feature Map) 생성
	- 크기를 유지하기 위해서는 패딩(padding)을 사용 
- 활용 분야: 컴퓨터 비전, CNN(합성곱 신경망)에서 이미지의 엣지 검출, 패턴 인식, 텍스처 분석 등
