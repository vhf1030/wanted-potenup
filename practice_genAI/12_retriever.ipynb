{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색기 - FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을 하나씩 추가하는 과정을 보여주어 초보자들이 코드를 이해하고 수정할 수 있도록 돕고자 합니다. 이 과정에서 기능 추가와 코드 관리의 중요성을 강조하며, 실습을 통해 학습할 수 있는 기회를 제공합니다.\\n\\n1. 영상 소개 및 목표'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content='오늘의 영상은 LML을 활용한 스트림 웹앱 서비스 제작에 대한 내용임.\\n이전 영상과 마찬가지로 백지에서 코드를 만들어 나가는 과정을 보여줄 예정임.\\n기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\\n레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.\\n코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.\\n\\n2. 기본 파일 구조'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content=\"'점 스트림'이라는 폴더를 만들고, 그 안에 'Secrets.toml' 파일을 생성함.\\n이 파일에는 오픈 AI 키를 넣어두고, 나중에 이를 가져와서 설정할 것임.\\n'메인.py' 파일 하나만 있으면 충분함.\\n\\n3. 단계적 개발 방법\\n\\n처음부터 완성형 서비스를 만들려고 하지 말고, 기본적인 수준부터 기능을 하나씩 추가하는 것이 좋음.\\n가장 쉬운 기능부터 시작하여 난이도를 높여가는 방식으로 진행함.\\n\\n4. 웹사이트 띄우기\"),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content=\"웹사이트를 띄우기 위해 기본적인 코드를 작성함.\\n'stre'를 임포트하고, 페이지 타이틀을 설정하는 코드 작성\\n기터 코파일럿을 사용하여 코드 자동 완성을 추천함.\\n서버를 올리고 웹사이트가 잘 구동되는지 확인함.\\n\\n5. 채팅 기능 구현\\n\\n채팅 기능을 구현하기 위해 스트림릿에서 제공하는 컴포넌트를 사용함.\\n'챗 인풋'과 '챗 메시지' 요소를 활용하여 채팅 기능을 구현할 것임.\\n스트림릿 공식 웹사이트에서 API 레퍼런스를 확인하여 예시 코드를 참고할 것을 권장함.\\n\\n6. 사용자 입력 처리\"),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content='사용자가 메시지를 입력할 수 있도록 지시문을 설정함.\\n입력된 메시지를 조건문을 통해 처리하고, 유저 아바타를 입혀서 출력함.\\n세션 스테이트를 사용하여 입력된 메시지를 기록하고, 페이지가 새로 고침되더라도 메시지를 유지할 수 있도록 함.\\n\\n7. AI 답변 처리\\n\\n사용자가 입력한 메시지에 대한 AI의 답변을 생성하는 로직을 구현함.\\n유저의 메시지를 출력한 후, AI의 답변을 추가로 출력하는 방식으로 진행함.\\n\\n8. 코드 정리 및 함수화'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content='출력하는 코드를 함수로 패키징하여 코드의 가독성을 높임.\\n챗 메시지를 튜플로 넣는 대신 객체화하여 가독성을 높이는 방법을 설명함.\\n\\n9. LLM 적용\\n\\nLLM을 적용하기 위해 필요한 코드와 설정을 설명함.\\n사용자가 입력한 내용을 기반으로 AI의 답변을 생성하는 과정을 구현함.\\n메모리 기능을 추가하여 대화 기록을 저장하고 활용할 수 있도록 함.\\n\\n10. 기능 추가 및 개선'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content='대화 기록을 로컬 DB에 저장하여 사용자가 다시 방문했을 때 이전 대화를 보여줄 수 있도록 함.\\n다양한 컴포넌트를 활용하여 기능을 추가하고 개선할 수 있는 방법을 제시함.\\n영상의 목적은 처음부터 구현하는 흐름을 보여주고, 기능 추가 및 오류 수정이 용이하도록 하는 것임.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"./data/langchain.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# db = FAISS.from_documents(\n",
    "#     documents=chunks,\n",
    "#     embedding=embedding\n",
    "# )\n",
    "retriever = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding\n",
    ").as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d8048f6f-ea86-4c6c-b446-8b139f2a884e', metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을 하나씩 추가하는 과정을 보여주어 초보자들이 코드를 이해하고 수정할 수 있도록 돕고자 합니다. 이 과정에서 기능 추가와 코드 관리의 중요성을 강조하며, 실습을 통해 학습할 수 있는 기회를 제공합니다.\\n\\n1. 영상 소개 및 목표'),\n",
       " Document(id='9ea8ac17-7dc1-4b0a-a272-c8ecb46e0d17', metadata={'source': './data/langchain.txt'}, page_content='오늘의 영상은 LML을 활용한 스트림 웹앱 서비스 제작에 대한 내용임.\\n이전 영상과 마찬가지로 백지에서 코드를 만들어 나가는 과정을 보여줄 예정임.\\n기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\\n레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.\\n코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.\\n\\n2. 기본 파일 구조'),\n",
       " Document(id='5f1bd279-58c1-45e7-8d7b-75d04bb5e5ed', metadata={'source': './data/langchain.txt'}, page_content='출력하는 코드를 함수로 패키징하여 코드의 가독성을 높임.\\n챗 메시지를 튜플로 넣는 대신 객체화하여 가독성을 높이는 방법을 설명함.\\n\\n9. LLM 적용\\n\\nLLM을 적용하기 위해 필요한 코드와 설정을 설명함.\\n사용자가 입력한 내용을 기반으로 AI의 답변을 생성하는 과정을 구현함.\\n메모리 기능을 추가하여 대화 기록을 저장하고 활용할 수 있도록 함.\\n\\n10. 기능 추가 및 개선'),\n",
       " Document(id='3e7ad4b5-6b51-42ea-9398-c52b56fe7f3a', metadata={'source': './data/langchain.txt'}, page_content='대화 기록을 로컬 DB에 저장하여 사용자가 다시 방문했을 때 이전 대화를 보여줄 수 있도록 함.\\n다양한 컴포넌트를 활용하여 기능을 추가하고 개선할 수 있는 방법을 제시함.\\n영상의 목적은 처음부터 구현하는 흐름을 보여주고, 기능 추가 및 오류 수정이 용이하도록 하는 것임.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke('langchain에 대해 알려줘')\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색기 - Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5ec85efc-6c5b-474b-a525-00a5d9854845', metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을 하나씩 추가하는 과정을 보여주어 초보자들이 코드를 이해하고 수정할 수 있도록 돕고자 합니다. 이 과정에서 기능 추가와 코드 관리의 중요성을 강조하며, 실습을 통해 학습할 수 있는 기회를 제공합니다.\\n\\n1. 영상 소개 및 목표'),\n",
       " Document(id='0eb77fb6-d368-4c17-a1bc-a2b651201593', metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을 하나씩 추가하는 과정을 보여주어 초보자들이 코드를 이해하고 수정할 수 있도록 돕고자 합니다. 이 과정에서 기능 추가와 코드 관리의 중요성을 강조하며, 실습을 통해 학습할 수 있는 기회를 제공합니다.\\n\\n1. 영상 소개 및 목표'),\n",
       " Document(id='c2a5e1e7-1b33-4ae2-805c-6ca4014741ef', metadata={'source': './data/langchain.txt'}, page_content='오늘의 영상은 LML을 활용한 스트림 웹앱 서비스 제작에 대한 내용임.\\n이전 영상과 마찬가지로 백지에서 코드를 만들어 나가는 과정을 보여줄 예정임.\\n기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\\n레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.\\n코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.\\n\\n2. 기본 파일 구조'),\n",
       " Document(id='c1743cf2-fea9-49b9-b18a-bb4d33ba1d6e', metadata={'source': './data/langchain.txt'}, page_content='오늘의 영상은 LML을 활용한 스트림 웹앱 서비스 제작에 대한 내용임.\\n이전 영상과 마찬가지로 백지에서 코드를 만들어 나가는 과정을 보여줄 예정임.\\n기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\\n레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.\\n코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.\\n\\n2. 기본 파일 구조')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "loader = TextLoader(\"./data/langchain.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "retriever = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory='./db/chroma_db',  # 저장 위치\n",
    "    collection_name='my_db3',  # 테이블명\n",
    ").as_retriever()\n",
    "\n",
    "docs = retriever.invoke('langchain에 대해 알려줘')\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문맥 압축 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을 하나씩 추가하는 과정을 보여주어 초보자들이 코드를 이해하고 수정할 수 있도록 돕고자 합니다.'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을 하나씩 추가하는 과정을 보여주어 초보자들이 코드를 이해하고 수정할 수 있도록 돕고자 합니다.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "comp_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever    \n",
    ")\n",
    "\n",
    "result = comp_retriever.invoke('langchain에 대해 알려줘')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 기반 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/langchain.txt'}, page_content='출력하는 코드를 함수로 패키징하여 코드의 가독성을 높임.\\n챗 메시지를 튜플로 넣는 대신 객체화하여 가독성을 높이는 방법을 설명함.\\n\\n9. LLM 적용\\n\\nLLM을 적용하기 위해 필요한 코드와 설정을 설명함.\\n사용자가 입력한 내용을 기반으로 AI의 답변을 생성하는 과정을 구현함.\\n메모리 기능을 추가하여 대화 기록을 저장하고 활용할 수 있도록 함.\\n\\n10. 기능 추가 및 개선'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content='사용자가 메시지를 입력할 수 있도록 지시문을 설정함.\\n입력된 메시지를 조건문을 통해 처리하고, 유저 아바타를 입혀서 출력함.\\n세션 스테이트를 사용하여 입력된 메시지를 기록하고, 페이지가 새로 고침되더라도 메시지를 유지할 수 있도록 함.\\n\\n7. AI 답변 처리\\n\\n사용자가 입력한 메시지에 대한 AI의 답변을 생성하는 로직을 구현함.\\n유저의 메시지를 출력한 후, AI의 답변을 추가로 출력하는 방식으로 진행함.\\n\\n8. 코드 정리 및 함수화'),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content=\"웹사이트를 띄우기 위해 기본적인 코드를 작성함.\\n'stre'를 임포트하고, 페이지 타이틀을 설정하는 코드 작성\\n기터 코파일럿을 사용하여 코드 자동 완성을 추천함.\\n서버를 올리고 웹사이트가 잘 구동되는지 확인함.\\n\\n5. 채팅 기능 구현\\n\\n채팅 기능을 구현하기 위해 스트림릿에서 제공하는 컴포넌트를 사용함.\\n'챗 인풋'과 '챗 메시지' 요소를 활용하여 채팅 기능을 구현할 것임.\\n스트림릿 공식 웹사이트에서 API 레퍼런스를 확인하여 예시 코드를 참고할 것을 권장함.\\n\\n6. 사용자 입력 처리\"),\n",
       " Document(metadata={'source': './data/langchain.txt'}, page_content=\"'점 스트림'이라는 폴더를 만들고, 그 안에 'Secrets.toml' 파일을 생성함.\\n이 파일에는 오픈 AI 키를 넣어두고, 나중에 이를 가져와서 설정할 것임.\\n'메인.py' 파일 하나만 있으면 충분함.\\n\\n3. 단계적 개발 방법\\n\\n처음부터 완성형 서비스를 만들려고 하지 말고, 기본적인 수준부터 기능을 하나씩 추가하는 것이 좋음.\\n가장 쉬운 기능부터 시작하여 난이도를 높여가는 방식으로 진행함.\\n\\n4. 웹사이트 띄우기\")]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "# documents = [\n",
    "#     \"langchain은 llm기반 응용 개발을 쉽게 한다.\",\n",
    "#     \"BM25Retriever는 키워드 기반 검색을 제공한다.\",\n",
    "#     \"Retriever는 문서 검색에 사용된다.\"\n",
    "# ]\n",
    "\n",
    "# bm25_retriever = BM25Retriever.from_texts(documents)\n",
    "# bm25_retriever.k = 2\n",
    "# result = bm25_retriever.get_relevant_documents('키워드 기반 검색기는?')\n",
    "\n",
    "loader = TextLoader(\"./data/langchain.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "result = bm25_retriever.get_relevant_documents('사용자 입력을 기반으로 AI 답변을 생성하려면?')\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='28da58c4-0e80-427a-b9ae-448f0c44f085', metadata={'source': './data/langchain.txt'}, page_content='사용자가 메시지를 입력할 수 있도록 지시문을 설정함.\\n입력된 메시지를 조건문을 통해 처리하고, 유저 아바타를 입혀서 출력함.\\n세션 스테이트를 사용하여 입력된 메시지를 기록하고, 페이지가 새로 고침되더라도 메시지를 유지할 수 있도록 함.\\n\\n7. AI 답변 처리\\n\\n사용자가 입력한 메시지에 대한 AI의 답변을 생성하는 로직을 구현함.\\n유저의 메시지를 출력한 후, AI의 답변을 추가로 출력하는 방식으로 진행함.\\n\\n8. 코드 정리 및 함수화'),\n",
       " Document(id='40a63054-e203-4afb-9c93-d8653ba75b65', metadata={'source': './data/langchain.txt'}, page_content='출력하는 코드를 함수로 패키징하여 코드의 가독성을 높임.\\n챗 메시지를 튜플로 넣는 대신 객체화하여 가독성을 높이는 방법을 설명함.\\n\\n9. LLM 적용\\n\\nLLM을 적용하기 위해 필요한 코드와 설정을 설명함.\\n사용자가 입력한 내용을 기반으로 AI의 답변을 생성하는 과정을 구현함.\\n메모리 기능을 추가하여 대화 기록을 저장하고 활용할 수 있도록 함.\\n\\n10. 기능 추가 및 개선'),\n",
       " Document(id='ded2751f-d6e9-4d26-9e4e-f3b3723a8308', metadata={'source': './data/langchain.txt'}, page_content=\"'점 스트림'이라는 폴더를 만들고, 그 안에 'Secrets.toml' 파일을 생성함.\\n이 파일에는 오픈 AI 키를 넣어두고, 나중에 이를 가져와서 설정할 것임.\\n'메인.py' 파일 하나만 있으면 충분함.\\n\\n3. 단계적 개발 방법\\n\\n처음부터 완성형 서비스를 만들려고 하지 말고, 기본적인 수준부터 기능을 하나씩 추가하는 것이 좋음.\\n가장 쉬운 기능부터 시작하여 난이도를 높여가는 방식으로 진행함.\\n\\n4. 웹사이트 띄우기\"),\n",
       " Document(id='3d0d730f-efb5-4e7d-8405-15627ef5b4b3', metadata={'source': './data/langchain.txt'}, page_content='대화 기록을 로컬 DB에 저장하여 사용자가 다시 방문했을 때 이전 대화를 보여줄 수 있도록 함.\\n다양한 컴포넌트를 활용하여 기능을 추가하고 개선할 수 있는 방법을 제시함.\\n영상의 목적은 처음부터 구현하는 흐름을 보여주고, 기능 추가 및 오류 수정이 용이하도록 하는 것임.'),\n",
       " Document(metadata={'source': 'google'}, page_content='Retriever는 문서 검색에 사용된다.'),\n",
       " Document(metadata={'source': 'docs'}, page_content='BM25Retriever는 키워드 기반 검색을 제공한다.'),\n",
       " Document(metadata={'source': 'blog'}, page_content='langchain은 llm기반 응용 개발을 쉽게 한다.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "###\n",
    "loader = TextLoader(\"./data/langchain.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "faiss_retriever = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding\n",
    ").as_retriever()\n",
    "\n",
    "###\n",
    "documents = [\n",
    "    Document(page_content=\"langchain은 llm기반 응용 개발을 쉽게 한다.\", metadata={'source': 'blog'}),\n",
    "    Document(page_content=\"BM25Retriever는 키워드 기반 검색을 제공한다.\", metadata={'source': 'docs'}),\n",
    "    Document(page_content=\"Retriever는 문서 검색에 사용된다.\", metadata={'source': 'google'}),\n",
    "]\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "\n",
    "###\n",
    "ensanble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.1, 0.9],\n",
    ")\n",
    "\n",
    "docs = ensanble_retriever.get_relevant_documents('사용자 입력을 기반으로 AI 답변을 생성하려면?')\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색 기능\n",
    "#### long context reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original\n",
      "검색결과 1:\t이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을\n",
      "검색결과 2:\t코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.\n",
      "검색결과 3:\t기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\n",
      "레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.\n",
      "검색결과 4:\t오늘의 영상은 LML을 활용한 스트림 웹앱 서비스 제작에 대한 내용임.\n",
      "이전 영상과 마찬가지로 백지에서 코드를 만들어 나가는 과정을 보여줄 예정임.\n",
      "\n",
      "reorder\n",
      "검색결과 1:\t코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.\n",
      "검색결과 2:\t오늘의 영상은 LML을 활용한 스트림 웹앱 서비스 제작에 대한 내용임.\n",
      "이전 영상과 마찬가지로 백지에서 코드를 만들어 나가는 과정을 보여줄 예정임.\n",
      "검색결과 3:\t기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\n",
      "레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.\n",
      "검색결과 4:\t이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "\n",
    "loader = TextLoader(\"./data/langchain.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "faiss_retriever = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding\n",
    ").as_retriever()\n",
    "\n",
    "results = faiss_retriever.invoke('langchain이란')\n",
    "print('\\noriginal')\n",
    "print('\\n'.join([f\"검색결과 {i+1}:\\t{r.page_content}\" for i, r in enumerate(results)]))\n",
    "\n",
    "reorder = LongContextReorder()\n",
    "results_reorder = reorder.transform_documents(results)\n",
    "print('\\nreorder')\n",
    "print('\\n'.join([f\"검색결과 {i+1}:\\t{r.page_content}\" for i, r in enumerate(results_reorder)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5ac21768-d011-4e1e-b05c-cc112663a50b', metadata={'source': './data/langchain.txt'}, page_content='이 영상은 LangChain을 활용하여 Streamlit으로 ChatGPT 클론 서비스를 만드는 방법을 단계별로 설명합니다. 강사는 코드를 처음부터 끝까지 직접 작성하며, 기능을'),\n",
       " Document(id='e2cb0896-da71-4b4a-a3e2-aab2babad8f7', metadata={'source': './data/langchain.txt'}, page_content='강조하며, 실습을 통해 학습할 수 있는 기회를 제공합니다.'),\n",
       " Document(id='0074bac4-666f-4d8a-88f4-5157783d2df3', metadata={'source': './data/langchain.txt'}, page_content='스트림릿 공식 웹사이트에서 API 레퍼런스를 확인하여 예시 코드를 참고할 것을 권장함.'),\n",
       " Document(id='5250eaee-15c3-4d5a-baf2-4af95951915b', metadata={'source': './data/langchain.txt'}, page_content='코딩에 익숙하지 않은 사람들을 위해 차근차근 과정을 설명할 것임.'),\n",
       " Document(id='6fbbf6e0-63be-429f-a2e3-5982f0ed6bfe', metadata={'source': './data/langchain.txt'}, page_content='기능을 하나씩 추가하며 ChatGPT와 유사한 서비스를 만드는 것이 목표임.\\n레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어려움.'),\n",
       " Document(id='374e9c97-430e-4fab-9489-2d8a97aeeff1', metadata={'source': './data/langchain.txt'}, page_content='영상의 목적은 처음부터 구현하는 흐름을 보여주고, 기능 추가 및 오류 수정이 용이하도록 하는 것임.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "\n",
    "multi_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=faiss_retriever,\n",
    "    llm=llm    \n",
    ")\n",
    "\n",
    "results = multi_retriever.invoke(\"langchain에 대해 알려줘\")\n",
    "results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### selfquery retriever\n",
    "- metadata, llm 활용\n",
    "```\n",
    "pip install lark\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"langchain은 llm기반 응용 개발을 쉽게 한다.\", metadata={'출판연도': 2023, '저자': '김상겸'}),\n",
    "    Document(page_content=\"BM25Retriever는 키워드 기반 검색을 제공한다.\", metadata={'출판연도': 2021, '저자': 'Best Match'}),\n",
    "    Document(page_content=\"Retriever는 문서 검색에 사용된다.\", metadata={'출판연도': 2025, '저자': 'Retriever'}),\n",
    "    Document(page_content=\"레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어렵다.\", metadata={'출판연도': 2025, '저자': 'Retriever'}),\n",
    "    Document(page_content=\"문서를 청크로 분할할 때, 인접 청크 간에 일정 부분 겹치는 영역을 포함시키면, 벡터 검색 시 유사도가 높은 청크를 검색할 때 이미 주변 문맥이 포함된 결과를 얻을 수 있습니다.\", metadata={'출판연도': 2025, '저자': 'Retriever'}),\n",
    "    Document(page_content=\"빛 신앙은 다키스트 던전 세계관 상에 존재하는 종교이다.\", metadata={'출판연도': 2021, '저자': '김상겸'}),\n",
    "    Document(page_content=\"작중 등장하는 종교적인 영웅으로 예루살렘 왕국의 왕을 모티브로 한 영웅이나 흑사병 시기에 고행으로 신의 분노를 달래려던 고행자 등이 나오는 것을 보면, 전체적인 이미지는 가톨릭을 모티브로 한 듯하다.\", metadata={'출판연도': 2021, '저자': '김상겸'}),\n",
    "    Document(page_content=\"게임 상에서 '종교적인(Religious)' 영웅으로 분류되는 영웅들은 모두 '빛'(The Light)이라는 개념을 섬기고 있다.\", metadata={'출판연도': 2021, '저자': '미상'}),\n",
    "    Document(page_content=\"빛 신앙을 상징하는 문장은 중심 원에서 상하좌우로 선이 뻗고, 각 선 끝에서 다시 양쪽으로 갈라지는 십자가 형태.\", metadata={'출판연도': 2021, '저자': '미상'}),\n",
    "]\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "metadata_info = [\n",
    "    AttributeInfo(name='출판연도', description='책이 출판된 연도', type='integer'),\n",
    "    AttributeInfo(name='저자', description='책의 저자', type='string'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [], 'embeddings': None, 'documents': [], 'uris': None, 'data': None, 'metadatas': [], 'included': [<IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "# 컬렉션 내 모든 문서의 ID를 조회합니다.\n",
    "all_docs = chroma_db._collection.get()\n",
    "print(all_docs)\n",
    "# all_ids = all_docs.get(\"ids\", [])\n",
    "\n",
    "# # 조회된 ID 목록을 이용해 문서들을 삭제합니다.\n",
    "# if all_ids:\n",
    "#     chroma_db._collection.delete(ids=all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2b34d7cf-7a6f-4cb8-90b0-4053958a356e', metadata={'저자': '김상겸', '출판연도': 2021}, page_content='빛 신앙은 다키스트 던전 세계관 상에 존재하는 종교이다.'),\n",
       " Document(id='c446c8fd-8b7d-40ed-b7fd-9b8cf5e9a0d0', metadata={'저자': '김상겸', '출판연도': 2021}, page_content='작중 등장하는 종교적인 영웅으로 예루살렘 왕국의 왕을 모티브로 한 영웅이나 흑사병 시기에 고행으로 신의 분노를 달래려던 고행자 등이 나오는 것을 보면, 전체적인 이미지는 가톨릭을 모티브로 한 듯하다.'),\n",
       " Document(id='7b80ef70-059a-4c03-b0a2-602c15f0bac0', metadata={'저자': '김상겸', '출판연도': 2023}, page_content='langchain은 llm기반 응용 개발을 쉽게 한다.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=chroma_db,\n",
    "    document_contents='기술과 관련된 책',\n",
    "    metadata_field_info=metadata_info\n",
    ")\n",
    "\n",
    "result = retriever.get_relevant_documents(\n",
    "    '저자가 김상겸인 책에서 다키스트 던전 관련 내용을 찾아줘'\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reranker\n",
    "```\n",
    "import os\n",
    "os.environ['HUGGING_FACE_HUB_TOKEN'] = ''\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''\n",
    "```\n",
    "- BAAI/bge-reranker-v2-m3의 경우 한국어를 지원하지 않음\n",
    "- 대안으로 cohere를 활용할 수 있으나 유료임 - Cohere/rerank-multilingual-v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original\n",
      "검색결과 1:\tlangchain은 llm기반 응용 개발을 쉽게 한다.\n",
      "검색결과 2:\t빛 신앙을 상징하는 문장은 중심 원에서 상하좌우로 선이 뻗고, 각 선 끝에서 다시 양쪽으로 갈라지는 십자가 형태.\n",
      "검색결과 3:\t빛 신앙은 다키스트 던전 세계관 상에 존재하는 종교이다.\n",
      "검색결과 4:\t문서를 청크로 분할할 때, 인접 청크 간에 일정 부분 겹치는 영역을 포함시키면, 벡터 검색 시 유사도가 높은 청크를 검색할 때 이미 주변 문맥이 포함된 결과를 얻을 수 있습니다.\n",
      "\n",
      "rerank\n",
      "검색결과 1:\tlangchain은 llm기반 응용 개발을 쉽게 한다.\n",
      "검색결과 2:\t문서를 청크로 분할할 때, 인접 청크 간에 일정 부분 겹치는 영역을 포함시키면, 벡터 검색 시 유사도가 높은 청크를 검색할 때 이미 주변 문맥이 포함된 결과를 얻을 수 있습니다.\n",
      "검색결과 3:\t빛 신앙은 다키스트 던전 세계관 상에 존재하는 종교이다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"langchain은 llm기반 응용 개발을 쉽게 한다.\", metadata={'출판연도': 2023, '저자': '김상겸'}),\n",
    "    Document(page_content=\"BM25Retriever는 키워드 기반 검색을 제공한다.\", metadata={'출판연도': 2021, '저자': 'Best Match'}),\n",
    "    Document(page_content=\"Retriever는 문서 검색에 사용된다.\", metadata={'출판연도': 2025, '저자': 'Retriever'}),\n",
    "    Document(page_content=\"레퍼런스 코드를 단순히 복사하여 붙여넣는 방식은 원하는 기능을 추가하기 어렵다.\", metadata={'출판연도': 2025, '저자': 'Retriever'}),\n",
    "    Document(page_content=\"문서를 청크로 분할할 때, 인접 청크 간에 일정 부분 겹치는 영역을 포함시키면, 벡터 검색 시 유사도가 높은 청크를 검색할 때 이미 주변 문맥이 포함된 결과를 얻을 수 있습니다.\", metadata={'출판연도': 2025, '저자': 'Retriever'}),\n",
    "    Document(page_content=\"빛 신앙은 다키스트 던전 세계관 상에 존재하는 종교이다.\", metadata={'출판연도': 2021, '저자': '김상겸'}),\n",
    "    Document(page_content=\"작중 등장하는 종교적인 영웅으로 예루살렘 왕국의 왕을 모티브로 한 영웅이나 흑사병 시기에 고행으로 신의 분노를 달래려던 고행자 등이 나오는 것을 보면, 전체적인 이미지는 가톨릭을 모티브로 한 듯하다.\", metadata={'출판연도': 2021, '저자': '김상겸'}),\n",
    "    Document(page_content=\"게임 상에서 '종교적인(Religious)' 영웅으로 분류되는 영웅들은 모두 '빛'(The Light)이라는 개념을 섬기고 있다.\", metadata={'출판연도': 2021, '저자': '미상'}),\n",
    "    Document(page_content=\"빛 신앙을 상징하는 문장은 중심 원에서 상하좌우로 선이 뻗고, 각 선 끝에서 다시 양쪽으로 갈라지는 십자가 형태.\", metadata={'출판연도': 2021, '저자': '미상'}),\n",
    "]\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "faiss_retriever = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding\n",
    ").as_retriever()\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name='BAAI/bge-reranker-v2-m3')\n",
    "\n",
    "compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "comp_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=faiss_retriever\n",
    ")\n",
    "\n",
    "results = faiss_retriever.invoke('langchain이란 무엇인가')\n",
    "print('\\noriginal')\n",
    "print('\\n'.join([f\"검색결과 {i+1}:\\t{r.page_content}\" for i, r in enumerate(results)]))\n",
    "\n",
    "results_rerank = comp_retriever.invoke('langchain이란 무엇인가')\n",
    "print('\\nrerank')\n",
    "print('\\n'.join([f\"검색결과 {i+1}:\\t{r.page_content}\" for i, r in enumerate(results_rerank)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contextual_window_size ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ContextualWindowRetriever' from 'langchain.retrievers' (c:\\Users\\user\\miniconda3\\envs\\lang_311\\Lib\\site-packages\\langchain\\retrievers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContextualWindowRetriever\n\u001b[32m      7\u001b[39m loader = TextLoader(\u001b[33m\"\u001b[39m\u001b[33m./data/langchain.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m text_splitter = RecursiveCharacterTextSplitter(\n\u001b[32m     10\u001b[39m     chunk_size=\u001b[32m30\u001b[39m,\n\u001b[32m     11\u001b[39m     chunk_overlap=\u001b[32m10\u001b[39m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ContextualWindowRetriever' from 'langchain.retrievers' (c:\\Users\\user\\miniconda3\\envs\\lang_311\\Lib\\site-packages\\langchain\\retrievers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ContextualWindowRetriever\n",
    "\n",
    "loader = TextLoader(\"./data/langchain.txt\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=30,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "len(chunks)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "faiss_retriever = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding\n",
    ").as_retriever()\n",
    "\n",
    "window_retriever = ContextualWindowRetriever(\n",
    "    base_retriever=faiss_retriever,\n",
    "    contextual_window_size=2  # 주변 2개의 청크를 함께 반환\n",
    ")\n",
    "\n",
    "result = retriever.invoke('langchain에 대해 알려줘')\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
